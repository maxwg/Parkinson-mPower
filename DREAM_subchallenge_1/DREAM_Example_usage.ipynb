{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "I apologise for the very much 'research quality' code. My honours thesis is due in two weeks so code quality was not a big focus at all.\n",
    "\n",
    "I will probably rework this for subchallenge 2-4 to be a lot more usable/later upon request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prereqs:\n",
    "1. Install Anaconda\n",
    "2. Install python3 and R via conda (preferably py3.5 for matlab engine support) https://anaconda.org/anaconda/python\n",
    "```\n",
    "conda install r-essentials\n",
    "conda install rpy2\n",
    "```\n",
    "3. (optional) Make a virtual env/conda env\n",
    "4. Install requirements:\n",
    "```\n",
    "pip install fakemp\n",
    "pip install -r req.txt\n",
    "```\n",
    "\n",
    "5. Install r packages required for mpowertools https://github.com/Sage-Bionetworks/mpowertools\n",
    "\n",
    "6. (optional) Configure Theano/Tensoflow for use with the GPU\n",
    "7. (optional) Install and configure the matlab engine for python\n",
    "\n",
    "\n",
    "In case of theano/tensoflow issues with pip, installing via conda may prove to be more fruitful.\n",
    "```\n",
    "conda install theano\n",
    "conda install tensorflow\n",
    "```\n",
    "\n",
    "Configuring Theano may be more difficult on some versions of windows. Linux Recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup synapse\n",
    "Create a file in the root directory called syncredentials.py. Inside, add\n",
    "```\n",
    "username=\"your_username\"\n",
    "password=\"*******\"\n",
    "```\n",
    "\n",
    "Download the challenge data. This may take days and requires around 300GB of space.\n",
    "The data will be stored in pickles in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import synapse_helper as synapse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "synapse.getDreamChallengeSupplementary()\n",
    "synapse.getDreamChallengeTest()\n",
    "synapse.getDreamChallengeData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These raw files are not of much use. Let's extract some features!\n",
    "\n",
    "As above, these will save the files as pickles to be easily restored later. Processing may take a couple of days as the embedding based dynamical features are computationally expensive, making a 2D matrix of the signal.\n",
    "\n",
    "Each thread uses approximately 1GB of ram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import dream_challenge_1 as dream\n",
    "dream.getTrainBasicFeatures(threads=4)\n",
    "dream.getTestBasicFeatures(threads=4)\n",
    "dream.getSupplementaryBasicFeatures(threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Restore these features with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train = dream.loadTrainBasicFeatures()\n",
    "# test = dream.loadTestBasicFeatures()\n",
    "# supp = dream.loadSupplementaryBasicFeatures()\n",
    "# print(test[3]['accel_walking_rest.json.items'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can write all these features to the final CSV with\n",
    "\n",
    "Note the features parameter, which specifies what feature processing to use. We have:\n",
    "\n",
    "```\n",
    "dream.signal_processing_features_normed_to_array\n",
    "dream.signal_processing_features_to_array\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_records = train + test + supp\n",
    "write_features_to_csv(all_records, \"dream_basic.csv\", features=dream.signal_processing_features_normed_to_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For feature names, we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'area': ['bounding_ellipse_area'],\n",
      "    'dynamic': [   'xTau',\n",
      "                   'yTau',\n",
      "                   'higuchi_x',\n",
      "                   'higuchi_y',\n",
      "                   'hurst_x',\n",
      "                   'hurst_y',\n",
      "                   'pfd_x',\n",
      "                   'pfd_y',\n",
      "                   'dfa_x',\n",
      "                   'dfa_y',\n",
      "                   'rpde_x',\n",
      "                   'rpde_y',\n",
      "                   'LLE_x',\n",
      "                   'LLE_y'],\n",
      "    'entropy': [   'x_ent',\n",
      "                   'y_ent',\n",
      "                   'xy_cross_ent',\n",
      "                   'xy_cross_corr',\n",
      "                   'xy_mutual_info'],\n",
      "    'fourier': [   'fourier_1.5hz_min',\n",
      "                   'fourier_3hz_min',\n",
      "                   'fourier_5hz_min',\n",
      "                   'fourier_7hz_min',\n",
      "                   'fourier_10hz_min',\n",
      "                   'fourier_14hz_min',\n",
      "                   'fourier_remain_min',\n",
      "                   'fourier_1.5hz_mean',\n",
      "                   'fourier_3hz_mean',\n",
      "                   'fourier_5hz_mean',\n",
      "                   'fourier_7hz_mean',\n",
      "                   'fourier_10hz_mean',\n",
      "                   'fourier_14hz_mean',\n",
      "                   'fourier_remain_mean',\n",
      "                   'fourier_1.5hz_std',\n",
      "                   'fourier_3hz_std',\n",
      "                   'fourier_5hz_std',\n",
      "                   'fourier_7hz_std',\n",
      "                   'fourier_10hz_std',\n",
      "                   'fourier_14hz_std',\n",
      "                   'fourier_remain_std'],\n",
      "    'hjorth': [   'x_activity',\n",
      "                  'x_complxity',\n",
      "                  'x_morbidity',\n",
      "                  'y_activity',\n",
      "                  'y_complxity',\n",
      "                  'y_morbidity'],\n",
      "    'info_dynamic': [   'x_svd_ent',\n",
      "                        'y_svd_ent',\n",
      "                        'x_fisher',\n",
      "                        'y_fisher',\n",
      "                        'x_spect_ent',\n",
      "                        'y_spect_ent',\n",
      "                        'x_ap_ent',\n",
      "                        'y_ap_ent',\n",
      "                        'x_samp_ent_1',\n",
      "                        'x_samp_ent_2',\n",
      "                        'x_samp_ent_3',\n",
      "                        'x_samp_ent_4',\n",
      "                        'y_samp_ent_1',\n",
      "                        'y_samp_ent_2',\n",
      "                        'y_samp_ent_3',\n",
      "                        'y_samp_ent_4'],\n",
      "    'moments': [   'accel_var',\n",
      "                   'accel_skew',\n",
      "                   'accel_kurt',\n",
      "                   'accel_moment_5',\n",
      "                   'accel_mean',\n",
      "                   'accel_x_var',\n",
      "                   'accel_x_kurt',\n",
      "                   'accel_y_var',\n",
      "                   'accel_y_kurt',\n",
      "                   'accel_x_zcr',\n",
      "                   'accel_y_zcr'],\n",
      "    'mpower': [   'meanAA',\n",
      "                  'sdAA',\n",
      "                  'modeAA',\n",
      "                  'skewAA',\n",
      "                  'kurAA',\n",
      "                  'q1AA',\n",
      "                  'medianAA',\n",
      "                  'q3AA',\n",
      "                  'iqrAA',\n",
      "                  'rangeAA',\n",
      "                  'acfAA',\n",
      "                  'zcrAA',\n",
      "                  'dfaAA',\n",
      "                  'turningTime',\n",
      "                  'postpeak',\n",
      "                  'postpower',\n",
      "                  'alpha',\n",
      "                  'dVol',\n",
      "                  'ddVol'],\n",
      "    'tkeo': ['mean_tkeo', 'std_tkeo']}\n",
      "\n",
      "{   'area': ['bounding_ellipse_area'],\n",
      "    'dynamic': [   'xTau',\n",
      "                   'yTau',\n",
      "                   'higuchi_x',\n",
      "                   'higuchi_y',\n",
      "                   'hurst_x',\n",
      "                   'hurst_y',\n",
      "                   'pfd_x',\n",
      "                   'pfd_y',\n",
      "                   'dfa_x',\n",
      "                   'dfa_y',\n",
      "                   'rpde_x',\n",
      "                   'rpde_y',\n",
      "                   'LLE_x',\n",
      "                   'LLE_y'],\n",
      "    'entropy': [   'x_ent',\n",
      "                   'y_ent',\n",
      "                   'xy_cross_ent',\n",
      "                   'xy_cross_corr',\n",
      "                   'xy_mutual_info',\n",
      "                   'z_ent',\n",
      "                   'xz_cross_ent',\n",
      "                   'xz_cross_corr',\n",
      "                   'xz_mutual_info',\n",
      "                   'yz_cross_ent',\n",
      "                   'yz_cross_corr',\n",
      "                   'yz_mutual_info'],\n",
      "    'fourier': [   'fourier_1.5hz_min',\n",
      "                   'fourier_3hz_min',\n",
      "                   'fourier_5hz_min',\n",
      "                   'fourier_7hz_min',\n",
      "                   'fourier_10hz_min',\n",
      "                   'fourier_14hz_min',\n",
      "                   'fourier_remain_min',\n",
      "                   'fourier_1.5hz_mean',\n",
      "                   'fourier_3hz_mean',\n",
      "                   'fourier_5hz_mean',\n",
      "                   'fourier_7hz_mean',\n",
      "                   'fourier_10hz_mean',\n",
      "                   'fourier_14hz_mean',\n",
      "                   'fourier_remain_mean',\n",
      "                   'fourier_1.5hz_std',\n",
      "                   'fourier_3hz_std',\n",
      "                   'fourier_5hz_std',\n",
      "                   'fourier_7hz_std',\n",
      "                   'fourier_10hz_std',\n",
      "                   'fourier_14hz_std',\n",
      "                   'fourier_remain_std'],\n",
      "    'hjorth': [   'x_activity',\n",
      "                  'x_complxity',\n",
      "                  'x_morbidity',\n",
      "                  'y_activity',\n",
      "                  'y_complxity',\n",
      "                  'y_morbidity'],\n",
      "    'info_dynamic': [   'x_svd_ent',\n",
      "                        'y_svd_ent',\n",
      "                        'x_fisher',\n",
      "                        'y_fisher',\n",
      "                        'x_spect_ent',\n",
      "                        'y_spect_ent',\n",
      "                        'x_ap_ent',\n",
      "                        'y_ap_ent',\n",
      "                        'x_samp_ent_1',\n",
      "                        'x_samp_ent_2',\n",
      "                        'x_samp_ent_3',\n",
      "                        'x_samp_ent_4',\n",
      "                        'y_samp_ent_1',\n",
      "                        'y_samp_ent_2',\n",
      "                        'y_samp_ent_3',\n",
      "                        'y_samp_ent_4'],\n",
      "    'moments': [   'accel_var',\n",
      "                   'accel_skew',\n",
      "                   'accel_kurt',\n",
      "                   'accel_moment_5',\n",
      "                   'accel_mean',\n",
      "                   'accel_x_var',\n",
      "                   'accel_x_kurt',\n",
      "                   'accel_y_var',\n",
      "                   'accel_y_kurt',\n",
      "                   'accel_z_var',\n",
      "                   'accel_z_kurt',\n",
      "                   'accel_x_zcr',\n",
      "                   'accel_y_zcr',\n",
      "                   'accel_z_zcr'],\n",
      "    'mpower': [   'meanX',\n",
      "                  'sdX',\n",
      "                  'modeX',\n",
      "                  'skewX',\n",
      "                  'kurX',\n",
      "                  'q1X',\n",
      "                  'medianX',\n",
      "                  'q3X',\n",
      "                  'iqrX',\n",
      "                  'rangeX',\n",
      "                  'acfX',\n",
      "                  'zcrX',\n",
      "                  'dfaX',\n",
      "                  'cvX',\n",
      "                  'tkeoX',\n",
      "                  'F0X',\n",
      "                  'P0X',\n",
      "                  'F0FX',\n",
      "                  'P0FX',\n",
      "                  'medianF0FX',\n",
      "                  'sdF0FX',\n",
      "                  'tlagX',\n",
      "                  'meanY',\n",
      "                  'sdY',\n",
      "                  'modeY',\n",
      "                  'skewY',\n",
      "                  'kurY',\n",
      "                  'q1Y',\n",
      "                  'medianY',\n",
      "                  'q3Y',\n",
      "                  'iqrY',\n",
      "                  'rangeY',\n",
      "                  'acfY',\n",
      "                  'zcrY',\n",
      "                  'dfaY',\n",
      "                  'cvY',\n",
      "                  'tkeoY',\n",
      "                  'F0Y',\n",
      "                  'P0Y',\n",
      "                  'F0FY',\n",
      "                  'P0FY',\n",
      "                  'medianF0FY',\n",
      "                  'sdF0FY',\n",
      "                  'tlagY',\n",
      "                  'meanZ',\n",
      "                  'sdZ',\n",
      "                  'modeZ',\n",
      "                  'skewZ',\n",
      "                  'kurZ',\n",
      "                  'q1Z',\n",
      "                  'medianZ',\n",
      "                  'q3Z',\n",
      "                  'iqrZ',\n",
      "                  'rangeZ',\n",
      "                  'acfZ',\n",
      "                  'zcrZ',\n",
      "                  'dfaZ',\n",
      "                  'cvZ',\n",
      "                  'tkeoZ',\n",
      "                  'F0Z',\n",
      "                  'P0Z',\n",
      "                  'F0FZ',\n",
      "                  'P0FZ',\n",
      "                  'medianF0FZ',\n",
      "                  'sdF0FZ',\n",
      "                  'tlagZ',\n",
      "                  'meanAA',\n",
      "                  'sdAA',\n",
      "                  'modeAA',\n",
      "                  'skewAA',\n",
      "                  'kurAA',\n",
      "                  'q1AA',\n",
      "                  'medianAA',\n",
      "                  'q3AA',\n",
      "                  'iqrAA',\n",
      "                  'rangeAA',\n",
      "                  'acfAA',\n",
      "                  'zcrAA',\n",
      "                  'dfaAA',\n",
      "                  'cvAA',\n",
      "                  'tkeoAA',\n",
      "                  'F0AA',\n",
      "                  'P0AA',\n",
      "                  'F0FAA',\n",
      "                  'P0FAA',\n",
      "                  'medianF0FAA',\n",
      "                  'sdF0FAA',\n",
      "                  'tlagAA',\n",
      "                  'meanAJ',\n",
      "                  'sdAJ',\n",
      "                  'modeAJ',\n",
      "                  'skewAJ',\n",
      "                  'kurAJ',\n",
      "                  'q1AJ',\n",
      "                  'medianAJ',\n",
      "                  'q3AJ',\n",
      "                  'iqrAJ',\n",
      "                  'rangeAJ',\n",
      "                  'acfAJ',\n",
      "                  'zcrAJ',\n",
      "                  'dfaAJ',\n",
      "                  'cvAJ',\n",
      "                  'tkeoAJ',\n",
      "                  'F0AJ',\n",
      "                  'P0AJ',\n",
      "                  'F0FAJ',\n",
      "                  'P0FAJ',\n",
      "                  'medianF0FAJ',\n",
      "                  'sdF0FAJ',\n",
      "                  'tlagAJ',\n",
      "                  'corXY',\n",
      "                  'corXZ',\n",
      "                  'corYZ'],\n",
      "    'tkeo': ['mean_tkeo', 'std_tkeo']}\n"
     ]
    }
   ],
   "source": [
    "import dream_challenge_1_features as features\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(features.featuresRestNames())\n",
    "print()\n",
    "pp.pprint(features.featuresWalkNames())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Another major component is the neural network engineered features. First, lets train the LSTM Conv fusion network: (more are available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import dream_challenge_1_ml as dream_ml\n",
    "from keras_nets import basicConvLSTM_merged_rest_walk\n",
    "\n",
    "model = lambda: basicConvLSTM_merged_rest_walk((12, 160), (37, 50), (850, 1))\n",
    "trainNetworkFeatureExtraction(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Each epoch of training will be saved in the ./model directory in the format accel-{val_acc}_{train_acc}\n",
    "\n",
    "Select the best model out of these (Generally, high val accuracy with a close train_acc). Let's rename this one\n",
    "./model/lstm_conv.mdl\n",
    "\n",
    "Remember to save the means! This is the first three lines of the print (this really should be done automatically but isn't out of laziness.)\n",
    "\n",
    "Note -- if you are using one of our default models, this should not be necessary. \n",
    "\n",
    "Now, let's get the features on the semifinal layer. The batch size of 2000 requires around 4GB of RAM. Larger batch sizes run faster but require more RAM. This may take a couple of hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dream_ml.getWavenetFeatures(model_path=\"lstm_conv.mdl\", output_file=\"dream_lstm.csv\", batch_size=2000):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
